{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WA3ztv-SU0uO"
   },
   "source": [
    "If you want to use this notebook online without installing Python on your computer, try:\n",
    "<a href=\"https://colab.research.google.com/github/WetSuiteLeiden/example-notebooks/blob/main/datasets-use/datasets-introduction-part-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> (do note however that this requires a Google account)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDSic6hRU0uP"
   },
   "source": [
    "# WetSuite datasets: introduction (part 1)\n",
    "\n",
    "WetSuite provides tools to more easily use existing legal datasets. In this series of example notebooks, we explain which datasets can be accessed via the `wetsuite-core` library, and how you can use this to leverage NLP tools in your legal research.\n",
    "\n",
    "## Types of legal datasets\n",
    "A lot of different legal datasets exist (TODO: reference the website here). The `wetsuite-core` library provides an easier interface to interact with some datasets. For each of these datasets, WetSuite also provides ready-made sample datasets which can help you practice your technical skills and show what's possible. The sample datasets are incomplete, as most datasets are quite big. Furthermore, the sample datasets won't be updated: they remain static. If you want to use the wetsuite-core library with more complete or up-to-date datasets, you will need to download this yourself (TODO: Reference how you can download other parts of the datasets yourself).\n",
    "\n",
    "## WetSuite sample datasets\n",
    "The sample datasets that are provided by WetSuite and accessible through the `wetsuite-core` exist to help you get started with programming and NLP research. The datasets are not complete and thus not fit to use in actual research. However, the datasets are based on larger and existing datasets which are complete and can be used for legal research. The things you learn in our notebooks should help you to create the tools you need for your research.\n",
    "\n",
    "The WetSuite sample datasets are:\n",
    "* Parliamentary data: a subset Dutch parliamentary data, in the XML format as provided by the Dutch government.\n",
    "* Court decisions: court decisions of about 2,5 year as provided by the Dutch Judicial Council (Raad voor de rechtspraak) in the original XML format.\n",
    "* Decisions by the Dutch Gambling Authority (Kansspelautoriteit) in a plaintext format\n",
    "* Dutch legislation in the XML format as provided by the Dutch government through the API's of wetten.overheid.nl.\n",
    "\n",
    "## Purpose of this notebook\n",
    "In this first part, we show how to install the `wetsuite-core` library for use in your Python Notebook (or project). Then we show how to interact with one of the ready-made sample datasets provided by WetSuite.\n",
    "\n",
    "## Target audience\n",
    "The primary target audience for this series of notebooks is legal scholars with little or no programming experience.\n",
    "\n",
    "## What you need\n",
    "You can read this notebook on GitHub as a reference. However, it is better to run it in order to get some actual programming experience. To run this notebook [TODO: link to how-to-run explanation].\n",
    "\n",
    "Besides this, the [Python documentation](https://docs.python.org/3/) can prove very helpful. If you want a more step-by-step and guided introduction to Python, plenty of online courses exists; for example [Codecademy's \"Learn Python 3\" course](https://www.codecademy.com/learn/learn-python-3).\n",
    "\n",
    "## Summary\n",
    "* WetSuite provides code to access some legal datasets in the `wetsuite-core` library.\n",
    "* WetSuite provides some small ready-made sample datasets which can also be accessed directly via the `wetsuite-core` library.\n",
    "* This series of notebooks aim to illustrate how to use Python to apply NLP-methods for legal research.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: What is a notebook?\n",
    "A Python Notebook, such as this file, is an interactive programming environment. It consists of blocks of text (such as this) and blocks of runnable Python code. When you run the notebook on your computer (or online in a service such as Google Colab), you can change the code and run it! The output of each code block is shown below the code block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2d35L3bcqhw"
   },
   "source": [
    "# Step 1: Using the `wetsuite-core` library\n",
    "\n",
    "In computer programming, a library is a collection of code that is meant to be re-used by other programs. The `wetsuite-core` library provides, among other things, interfaces to interact in a practical manner directly with some existing legal datasets which are made available online. For example, you can easily download all published judgments by a specific court in the Netherlands as made available by the Raad voor de rechtspraak.\n",
    "\n",
    "In order to use the `wetsuite-core` library, download and install the library by running the following code block:\n",
    "\n",
    "(TODO: also add documentation on how to run this locally?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zda46Be8U0uS"
   },
   "outputs": [],
   "source": [
    "# (only) in colab, run this first to install wetsuite from (the most recent) source.   For your own setup, see wetsuite's install guidelines.\n",
    "!pip3 install -U wetsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the wetsuite library is installed, we can import it in our Python Notebook or file. Importing a library allows you to use the functions defined in the library in your program. In this notebook, we will use the datasets part of `wetsuite-core`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1h4H0pVU0uT",
    "outputId": "2c0790c5-6558-4a27-ead8-7bd16da2ebf1"
   },
   "outputs": [],
   "source": [
    "import wetsuite.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about what features are made available through the `wetsuite-core` library, you can visit the [WetSuite API documentation](https://wetsuite.knobs-dials.com/apidocs/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Finding a sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a library is imported, we can use it in our program. By calling the following function, we can see which sample datasets are currently available. Please note that it might change over time which sample datasets are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bwb-mostrecent-meta-struc',\n",
       " 'bwb-mostrecent-text',\n",
       " 'bwb-mostrecent-xml',\n",
       " 'cvdr-mostrecent-html',\n",
       " 'cvdr-mostrecent-meta-struc',\n",
       " 'cvdr-mostrecent-text',\n",
       " 'cvdr-mostrecent-xml',\n",
       " 'eurlex-dir-nl-struc',\n",
       " 'eurlex-judg-nl-struc',\n",
       " 'eurlex-reg-nl-struc',\n",
       " 'gemeentes-struc',\n",
       " 'internetconsultaties-partial-struc',\n",
       " 'kansspelautoriteit-sancties-struc',\n",
       " 'parliament-sample-xml',\n",
       " 'raadvanstate-adviezen-struc',\n",
       " 'rechtspraaknl-sample-xml',\n",
       " 'rechtspraaknl-struc',\n",
       " 'tweedekamer-fractie-membership-struc',\n",
       " 'tweedekamer-fracties-struc',\n",
       " 'tweedekamer-kamervragen-struc',\n",
       " 'wetnamen',\n",
       " 'woo_besluiten_docs_text',\n",
       " 'woo_besluiten_meta']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wetsuite.datasets.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample dataset also has a short (and longer) description, and we can see what the size is of each dataset.\n",
    "\n",
    "You can get that in a machine-readable format by running: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'rechtspraaknl-sample-xml',\n",
       " 'url': 'https://wetsuite.knobs-dials.com/datasets/rechtspraaknl-sample-xml.db.xz',\n",
       " 'version': '(preliminary)',\n",
       " 'type': 'xz-sqlite3',\n",
       " 'description_short': ' A small sample of the XML form available at rechtspraak.nl: documents from 2022 on ',\n",
       " 'description': ' (TODO) ',\n",
       " 'download_size': 461388184,\n",
       " 'real_size': 4241199104,\n",
       " 'download_size_human': '440MiB',\n",
       " 'real_size_human': '3.9GiB',\n",
       " 'uncompressed_sha1hex': 'e60a32ad72d5068e991ad7f05233dd9fe0846af1',\n",
       " 'first100000_sha1hex': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the index information in the form of a dictionary\n",
    "datasets_index = wetsuite.datasets.fetch_index()\n",
    "\n",
    "# Get the information of this specific dataset.\n",
    "datasets_index[\"rechtspraaknl-sample-xml\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also a separate function to give a human-readable overview of all the available datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNy-7ETmU0uU",
    "outputId": "c0b7a475-5a7c-4b70-b66e-87f56b1bc318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bwb-mostrecent-meta-struc               \t  186MiB\tMetadata structure text for the latest revision from each BWB-id\n",
      "bwb-mostrecent-text                     \t  393MiB\tPlain text for the latest revision from each BWB-id\n",
      "bwb-mostrecent-xml                      \t  2.9GiB\tRaw XML for the latest revision from each BWB-id\n",
      "cvdr-mostrecent-html                    \t 14.3GiB\tRaw HTML for the latest expression within each CVDR work set\n",
      "cvdr-mostrecent-meta-struc              \t  259MiB\tMetadata for the latest expression within each CVDR work set\n",
      "cvdr-mostrecent-text                    \t  3.8GiB\tFlattened plain text for the latest expression within each CVDR work set\n",
      "cvdr-mostrecent-xml                     \t  8.7GiB\tRaw XML for the latest expression within each CVDR work set\n",
      "eurlex-dir-nl-struc                     \t  213MiB\tThe dutch translation of metadata and text for European DIRectives in EUR-LEX. (preliminary version)\n",
      "eurlex-judg-nl-struc                    \t  0.9GiB\tThe dutch translation of metadata and text for European JUDGments in EUR-LEX. (preliminary version)\n",
      "eurlex-reg-nl-struc                     \t  1.4GiB\tThe dutch translation of metadata and text for European REGulations in EUR-LEX. (preliminary version)\n",
      "gemeentes-struc                         \t  374KiB\tA list of gemeentes, and some details about each.\n",
      "internetconsultaties-partial-struc      \t   82MiB\tThe text contents of a good portion of the answers at https://www.internetconsultatie.nl\n",
      "kansspelautoriteit-sancties-struc       \t  8.8MiB\tMetadata and plain text form of the set of PDFs you can find under https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/ \n",
      "parliament-sample-xml                   \t  1.7GiB\tA moderate-sized collection of kamerstukken, handelingen, and aanhangsels\n",
      "raadvanstate-adviezen-struc             \t  140MiB\tA parsed, plain-text form of Raad van State (state council) advice, specifically the set of documents under https://www.raadvanstate.nl/adviezen\n",
      "rechtspraaknl-sample-xml                \t  3.9GiB\t A small sample of the XML form available at rechtspraak.nl: documents from 2022 on \n",
      "rechtspraaknl-struc                     \t 12.3GiB\tNone\n",
      "tweedekamer-fractie-membership-struc    \t  800KiB\tDescription of people, including party memberships over time.\n",
      "tweedekamer-fracties-struc              \t   72KiB\tDescription of political parties/fracties.\n",
      "tweedekamer-kamervragen-struc           \t  606MiB\t Questions from members of the parliament (tweede kamer) to the government. \n",
      "wetnamen                                \t  6.5MiB\tA name for each BWB-ID\n",
      "woo_besluiten_docs_text                 \t  123MiB\tNone\n",
      "woo_besluiten_meta                      \t    3MiB\tNone\n"
     ]
    }
   ],
   "source": [
    "wetsuite.datasets.print_dataset_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset available through the wetsuite library, there is also an extended description. This is also part of the index, and can be accessed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a plaintext form of the set of documents you can find under https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/ as PDFs.\n",
      "\n",
      "        Since almost half of those PDFs do not have a text stream, this data is entirely OCR'd,\n",
      "        so expect some typical OCR errors.  The OCR quality seems fairly decent, and some effort was made to remove headers and footers,\n",
      "        yet there are some leftovers  like _ instead of . and = instead of :\n",
      "\n",
      "\n",
      "        The data is a fairly nested structure of python objects (or JSON, before it's parsed).\n",
      "        - .data is a list of cases.\n",
      "\n",
      "        - each case is a dict, with a \n",
      "            - 'name', \n",
      "            - 'docs' (a list) \n",
      "            - and some extracted information like mentioned money amounts, the apparent date span of the case\n",
      "\n",
      "        - each document in that mentioned list is is a dict, with keys like\n",
      "            - 'url' - to the PDF it came from\n",
      "            - 'status' - from the detail page (if we could find it - not 100%) \n",
      "            - extracted informations like 'header_dates' (comes from PDF contents)\n",
      "            - 'pages' (a list)\n",
      "\n",
      "        - each page in that list is a dict, which has keys:\n",
      "            - 'body_text' - a list, which containts text fragments that are _almost_ like paragraphs \n",
      "                except that text may continue between pages anyway - currently still up to you to detect - \n",
      "                plus the post-OCR processing isn't perfect.\n",
      "            - 'foot_text' - generally just [ \"Pagina 1 van 27\" ]\n",
      "            - 'head_text' - fragments like []\"Kansspelautoriteit\", \"OPENBAAR\"] but also the date and kenmerk lines\n",
      "\n",
      "\n",
      "        (TODO: update this example)\n",
      "        For example (body text edited for brevity), one case's dict, with one document:\n",
      "            { # dict for a case\n",
      "                'name': 'Toto Online B.V.',  # case's name\n",
      "                'docs': [                    # list of PDF documents in this case\n",
      "                    { # dict detailing first document in case\n",
      "                        'url': 'https://kansspelautoriteit.nl/publish/library/32/01_278_071_15091_sanctiebesluit_toto_ov.pdf',\n",
      "                        'pages': [\n",
      "                            {  # first page's dict   (currently contains only body's text fragments; idea was to split off header contents)\n",
      "                                'body_text':[  # first page's text fragments\n",
      "                                    'Besluit van de raad van [more sentence]',\n",
      "                                    'Zaak: 15091 Kenmerk: 15091 [more kenmerk]',\n",
      "                                    'Besluit',\n",
      "                                    'Inleiding',\n",
      "                                    'De raad van bestuur van de Kansspelautoriteit [more paragraph]'\n",
      "                                ]\n",
      "                            },\n",
      "                            { # second page's dict\n",
      "                                'body_text': [   # second page text fragment\n",
      "                                'heeft heeft ontvangen sinds hij daar [more paragraph]',\n",
      "                                'De toezichthouders zijn naar aanleiding [more paragraph]'\n",
      "                                ]\n",
      "                            } \n",
      "                            # ...more pages\n",
      "                        ], \n",
      "                    }, # end of document dict\n",
      "                    # ...more documents\n",
      "                ]\n",
      "            }\n",
      "        This dataset was generated on 2024-03-15\n"
     ]
    }
   ],
   "source": [
    "# Note that we've defined the datasets_index variable before.\n",
    "\n",
    "print(datasets_index[\"kansspelautoriteit-sancties-struc\"][\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Downloading and accessing a sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know which sample datasets are available, we can choose to download one. For this notebook, we'll delve deeper into the `kansspelautoriteit-sancties-struc` dataset. This dataset contains all decisions published by the Dutch Gambling Authority (Kansspelautoriteit, abbreviated to _Ksa_ for short). These documents have already been pre-processed: the text has been extracted from the PDF files published by the Ksa and some metadata is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzNPJd9PU0uV",
    "outputId": "a32b58c6-9264-4e72-f9d7-8090a3484098"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wetsuite.datasets.Dataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "ksa = wetsuite.datasets.load(\"kansspelautoriteit-sancties-struc\")\n",
    "type(ksa)\n",
    "# The object returned by this load function is an object of the custom Dataset class, the documentation\n",
    "# of which can be found here: https://wetsuite.knobs-dials.com/apidocs/wetsuite.datasets.Dataset.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WetSuite library provides a small abstraction layer to make it easier to handle your data and focus more on creating your experiment. However, using this method of accessing certain datasets is certainly not required. When you are building your own datasets, or using datasets from other sources, you might need to interface in a different way with your data.\n",
    "\n",
    "For each `Dataset` object, the actual data can be found in its `.data` variable, which contains a simple key-value store (specifically, it's of type [`wetsuite.helpers.localdata.LocalKV`](https://wetsuite.knobs-dials.com/apidocs/wetsuite.helpers.localdata.LocalKV.html)). You can see a key-value store as essentially a dictionary: given a specific key, you will get the associated data (the value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/1x-corp-exinvest/\n",
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/7red-com/\n",
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/artikel/\n",
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/aulon/\n",
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/automaten/\n",
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/bankgiro-loterij/\n",
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/belhuis-internetcafe/\n",
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/bet-at-home/\n",
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/betent-0/\n",
      "https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/betent-aanwijzing/\n"
     ]
    }
   ],
   "source": [
    "# Convert the keys iterable to a list\n",
    "keys_list = list(ksa.data.keys())\n",
    "\n",
    "# Print the first ten keys in the ksa dataset\n",
    "for k in keys_list[0:10]:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LocalKV` class also provides some helper functions, for example to get a random sample of keys.\n",
    "\n",
    "Now that we know which keys are available in our dataset, we can see what values are actually available for each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ksa.data.get(\n",
    "    \"https://kansspelautoriteit.nl/aanpak-misstanden/sanctiebesluiten/bankgiro-loterij/\"\n",
    ")\n",
    "# The output is pretty long, so it's commented out here. Uncomment it and run it to check it out!\n",
    "# pprint.pprint(v)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
