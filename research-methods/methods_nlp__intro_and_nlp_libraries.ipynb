{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3NCj8rkQMsdx"
   },
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "To be a brief comparison to packages that provide more generic NLP functionality. \n",
    "\n",
    "These days there are quite a few, and we can only point out there is no shortage of choices.\n",
    "\n",
    "We use spacy, as it seems like a convenient generic choice to us,\n",
    "yet most of the things it does are also done - sometimes better - by other choices.\n",
    "This list is not an endorsement of any - it ends up depending on how your purposes match their specialization.\n",
    "\n",
    "Choices include, in no particular order:\n",
    "\n",
    "- [spacy](https://spacy.io/usage/spacy-101) - see also our own [methods_nlp__spacy_basics](methods_nlp__spacy_basics.ipynb)\n",
    "  - ~two dozen languages, including Dutch\n",
    "\n",
    "- [pattern](https://github.com/clips/pattern)\n",
    "  - 6 languages, including Dutch\n",
    "\n",
    "- [flair](https://github.com/flairNLP/flair)\n",
    "  - 4 languages, including Dutch\n",
    "\n",
    "- [stanza](https://stanfordnlp.github.io/stanza/)\n",
    "  - ~80 languages, including Dutch\n",
    "  - and note there is e.g. a [spacy-stanza](https://spacy.io/universe/project/spacy-stanza/)\n",
    "\n",
    "- [UDPipe](https://lindat.mff.cuni.cz/services/udpipe/)\n",
    "  - various languages, including Dutch\n",
    "  - and note there is a [spacy-udpipe](https://spacy.io/universe/project/spacy-udpipe)\n",
    "\n",
    "- [alpino](https://www.let.rug.nl/vannoord/alp/Alpino/)\n",
    "  - and note there is e.g. a [spacy-alpino](https://pypi.org/project/spacy-alpino/)\n",
    "\n",
    "- [trankit](https://github.com/nlp-uoregon/trankit)\n",
    "  - 50+ languages, including Dutch \n",
    "  - and note there is e.g. a [spacy-trankit](https://pypi.org/project/spacy-trankit/)\n",
    "\n",
    "- [nltk](https://www.nltk.org/)\n",
    "  - different components seem to support different languages, Dutch is not supported in all of them out-of-the-box\n",
    "  - though [training basic support is relatively simple](https://stackoverflow.com/questions/40212895/nltk-tag-dutch-sentence)\n",
    "\n",
    "- [textblob](https://textblob.readthedocs.io/en/dev/) \n",
    "  - language-extensible, but out of the box it seems to focus just on English\n",
    "  - so no Dutch support, though [there's this](https://github.com/gvisniuc/textblob-nl)\n",
    "\n",
    "- [CoreNLP](https://stanfordnlp.github.io/CoreNLP/)\n",
    "  - 8 languages, no Dutch\n",
    "\n",
    "- [NLP-Cube](https://github.com/Adobe/NLP-Cube)\n",
    "  - 8 languags (?), no Dutch?\n",
    "\n",
    "...in part just to mention them, in part to help you choose one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some minimal examples\n",
    "\n",
    "This is not highlighting any library's speciality, \n",
    "it's here primarily to highlight that the bare minimum in any of these libraries is simple to get started with.\n",
    "\n",
    "You still need decide what you need most, and find out how well each of them does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "test = \"Python is a high-level, general-purpose programming language. It can be quite useful.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qKsX4tkxMsd0"
   },
   "source": [
    "## spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 'PROPN'), ('is', 'AUX'), ('a', 'DET'), ('high', 'ADJ'), ('-', 'PUNCT'), ('level', 'NOUN'), (',', 'PUNCT'), ('general', 'ADJ'), ('-', 'PUNCT'), ('purpose', 'NOUN'), ('programming', 'NOUN'), ('language', 'NOUN'), ('.', 'PUNCT'), ('It', 'PRON'), ('can', 'AUX'), ('be', 'AUX'), ('quite', 'ADV'), ('useful', 'ADJ'), ('.', 'PUNCT')]\n",
      "SENT:  Python is a high-level, general-purpose programming language.\n",
      "SENT:  It can be quite useful.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "english_lg  = spacy.load('en_core_web_lg')   \n",
    "\n",
    "ana = english_lg( test )\n",
    "\n",
    "print( list( (tok.text, tok.pos_)  for tok in ana ) )\n",
    "for sent in ana.sents:\n",
    "    print( \"SENT: \",sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textblob\n",
    "\n",
    "See also https://textblob.readthedocs.io/en/dev/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('high-level', 'JJ'), ('general-purpose', 'JJ'), ('programming', 'NN'), ('language', 'NN'), ('It', 'PRP'), ('can', 'MD'), ('be', 'VB'), ('quite', 'RB'), ('useful', 'JJ')]\n",
      "[Sentence(\"Python is a high-level, general-purpose programming language.\"), Sentence(\"It can be quite useful.\")]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "ana = TextBlob( test )\n",
    "\n",
    "print(ana.tags)\n",
    "print(ana.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('high-level', 'JJ'), (',', ','), ('general-purpose', 'JJ'), ('programming', 'NN'), ('language', 'NN'), ('.', '.'), ('It', 'PRP'), ('can', 'MD'), ('be', 'VB'), ('quite', 'RB'), ('useful', 'JJ'), ('.', '.')]\n",
      "['Python is a high-level, general-purpose programming language.', 'It can be quite useful.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "\n",
    "print( pos_tag( word_tokenize(test) ) )\n",
    "print( sent_tokenize(test) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import parse # in this project you'ld mainly use pattern.nl instead\n",
    "ana = parse(test,\n",
    "     tokenize = True,  \n",
    "         tags = True,  \n",
    "       chunks = True,  \n",
    "    relations = True,\n",
    "      #lemmata = True,  \n",
    "        light = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Python', 'NNP', 'B-NP', 'O', 'NP-SBJ-1'],\n",
      "  ['is', 'VBZ', 'B-VP', 'O', 'VP-1'],\n",
      "  ['a', 'DT', 'B-NP', 'O', 'NP-OBJ-1'],\n",
      "  ['high-level', 'JJ', 'I-NP', 'O', 'NP-OBJ-1'],\n",
      "  [',', ',', 'I-NP', 'O', 'NP-OBJ-1'],\n",
      "  ['general-purpose', 'JJ', 'I-NP', 'O', 'NP-OBJ-1'],\n",
      "  ['programming', 'NN', 'I-NP', 'O', 'NP-OBJ-1'],\n",
      "  ['language', 'NN', 'I-NP', 'O', 'NP-OBJ-1'],\n",
      "  ['.', '.', 'O', 'O', 'O']],\n",
      " [['It', 'PRP', 'B-NP', 'O', 'NP-SBJ-1'],\n",
      "  ['can', 'MD', 'B-VP', 'O', 'VP-1'],\n",
      "  ['be', 'VB', 'I-VP', 'O', 'VP-1'],\n",
      "  ['quite', 'RB', 'B-ADJP', 'O', 'O'],\n",
      "  ['useful', 'JJ', 'I-ADJP', 'O', 'O'],\n",
      "  ['.', '.', 'O', 'O', 'O']]]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint( ana.split() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-01 15:14:35,772 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence[7]: \"De minister kan in Parijs opduiken.\" â†’ [\"Parijs\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('De minister kan in Parijs opduiken.',language_code='nl')\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = Classifier.load('ner')\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print the sentence with all annotations\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreNLP\n",
    "\n",
    "CoreNLP is a java server that can be queried from a java client.\n",
    "\n",
    "...or libraries like [corenlp-client](https://pypi.org/project/corenlp-client/).\n",
    "\n",
    "<!--\n",
    "That means [its install](https://stanfordnlp.github.io/CoreNLP/download.html)\n",
    "\n",
    "-->\n",
    "\n",
    "See also https://stanfordnlp.github.io/CoreNLP/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinations\n",
    "\n",
    "There are various efforts to combine the outputs of different libraries, \n",
    "particularly where they achieve different things.\n",
    "\n",
    "From what we've seen, many of these now seemsto be \"let's duct tape it onto spacy\" efforts,\n",
    "which often tries to integrate it into spacy's \"a Document is a series ot Tokens and Spans\" view.\n",
    "\n",
    "* some of these primarily put the same interface (a Document of Tokens and extra annotations) so that existing spacy code can, as-is, now talk to what under the covers is something else (e.g. spacy-stanza, spacy-udpipe) \n",
    "* Some of these are feature additions, e.g. adding specific annotations to existing pipelines \n",
    "* some are messier and definitely earn the 'duct taped' description.\n",
    "\n",
    "Quite a few of these these can be found in [this project list](https://spacy.io/universe)\n",
    "\n",
    "Note that the examples below are _not_ meant as a full list of options, just as examples of some added usefulness (_and_ of that duct tape)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy-stanza \n",
    "\n",
    "https://spacy.io/universe/project/spacy-stanza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plain stanza already looks similar:\n",
    "import stanza\n",
    "stanza.download('nl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"De\",\n",
      "      \"lemma\": \"de\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"LID|bep|stan|rest\",\n",
      "      \"feats\": \"Definite=Def\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 0,\n",
      "      \"end_char\": 2,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"minister\",\n",
      "      \"lemma\": \"minister\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"N|soort|ev|basis|zijd|stan\",\n",
      "      \"feats\": \"Gender=Com|Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 3,\n",
      "      \"end_char\": 11,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"kan\",\n",
      "      \"lemma\": \"kunnen\",\n",
      "      \"upos\": \"AUX\",\n",
      "      \"xpos\": \"WW|pv|tgw|ev\",\n",
      "      \"feats\": \"Number=Sing|Tense=Pres|VerbForm=Fin\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"aux\",\n",
      "      \"start_char\": 12,\n",
      "      \"end_char\": 15,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"in\",\n",
      "      \"lemma\": \"in\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"VZ|init\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 16,\n",
      "      \"end_char\": 18,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"Parijs\",\n",
      "      \"lemma\": \"Parijs\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"N|eigen|ev|basis|onz|stan\",\n",
      "      \"feats\": \"Gender=Neut|Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 19,\n",
      "      \"end_char\": 25,\n",
      "      \"ner\": \"S-LOC\",\n",
      "      \"multi_ner\": [\n",
      "        \"S-LOC\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"opduiken\",\n",
      "      \"lemma\": \"op_duiken\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"WW|inf|vrij|zonder\",\n",
      "      \"feats\": \"VerbForm=Inf\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 26,\n",
      "      \"end_char\": 34,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \"LET\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 34,\n",
      "      \"end_char\": 35,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{\n",
       "   \"text\": \"Parijs\",\n",
       "   \"type\": \"LOC\",\n",
       "   \"start_char\": 19,\n",
       "   \"end_char\": 25\n",
       " }]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reference, this is what bare stanza outputs\n",
    "nlp = stanza.Pipeline('nl',logging_level='ERROR')\n",
    "doc = nlp(\"De minister kan in Parijs opduiken.\") # run annotation over a sentence\n",
    "print( doc )\n",
    "#print( doc.entities )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install spacy_stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['De', 'de', 'DET', 'det', '']\n",
      "['minister', 'minister', 'NOUN', 'nsubj', '']\n",
      "['kan', 'kunnen', 'AUX', 'aux', '']\n",
      "['in', 'in', 'ADP', 'case', '']\n",
      "['Parijs', 'Parijs', 'PROPN', 'obl', 'LOC']\n",
      "['opduiken', 'op_duiken', 'VERB', 'root', '']\n",
      "['.', '.', 'PUNCT', 'punct', '']\n",
      "['Parijs', 'LOC']\n"
     ]
    }
   ],
   "source": [
    "# spacy-stanza makes that act like spacy\n",
    "import stanza\n",
    "import spacy_stanza\n",
    "\n",
    "stanza.download(\"nl\")\n",
    "nlp = spacy_stanza.load_pipeline(\"nl\")\n",
    "\n",
    "doc = nlp(\"De minister kan in Parijs opduiken.\")\n",
    "for token in doc:\n",
    "    print( [token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_] )\n",
    "for ent in doc.ents:\n",
    "    print( [ent.text, ent.label_] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy-benepar, and adding some nltk, why not\n",
    "\n",
    "(Note that benepar does not have a Dutch model, so isn't directly relevant to this project)\n",
    "\n",
    "\n",
    "Spacy has a dependency parser, but not a constituency parser.\n",
    "\n",
    "Constituency parsers give the more classical \"verb phrase containing a noun phrase\" view on sentences. \n",
    "These have fallen out of style somewhat, and there isn't a high quality one for every language,\n",
    "but they definitely still have their uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install benepar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import benepar, spacy, nltk\n",
    "\n",
    "bpname = 'benepar_en3'\n",
    "benepar.download( bpname )\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "if spacy.__version__.startswith('2'):\n",
    "    nlp.add_pipe(benepar.BeneparComponent(bpname))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\":bpname})\n",
    "\n",
    "doc = nlp(\"I like cheese and you like ham.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"264px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,344.0,264.0\" width=\"344px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"44.186%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"26.3158%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">I</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.1579%\" y1=\"20px\" y2=\"48px\" /><svg width=\"73.6842%\" x=\"26.3158%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"42.8571%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">like</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.4286%\" y1=\"20px\" y2=\"48px\" /><svg width=\"57.1429%\" x=\"42.8571%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">cheese</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.4286%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.1579%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.093%\" y1=\"20px\" y2=\"48px\" /><svg width=\"11.6279%\" x=\"44.186%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CC</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">and</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /><svg width=\"37.2093%\" x=\"55.814%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"31.25%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">you</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.625%\" y1=\"20px\" y2=\"48px\" /><svg width=\"68.75%\" x=\"31.25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"54.5455%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">like</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.2727%\" y1=\"20px\" y2=\"48px\" /><svg width=\"45.4545%\" x=\"54.5455%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ham</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.2727%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.625%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"74.4186%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.97674%\" x=\"93.0233%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.5116%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('S', [Tree('NP', [Tree('PRP', ['I'])]), Tree('VP', [Tree('VBP', ['like']), Tree('NP', [Tree('NN', ['cheese'])])])]), Tree('CC', ['and']), Tree('S', [Tree('NP', [Tree('PRP', ['you'])]), Tree('VP', [Tree('VBP', ['like']), Tree('NP', [Tree('NN', ['ham'])])])]), Tree('.', ['.'])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like cheese and /\n",
      "you like ham . /\n"
     ]
    }
   ],
   "source": [
    "for sent in list(doc.sents):\n",
    "    # let's estimate how wel we might split a senteence, using a constituency parse   \n",
    "    # Instead of estimating clauses (which has plenty of edge cases),\n",
    "    #   this basically counts the amount of brackets at each token position (and remembering that in terms of token index)\n",
    "    #   Every time a bunch of brackets are closed at once, we decide we might split there.\n",
    "    # You _can_ interrogate sent._.constituents for this, and this is arguably a less error-prone thing to do.\n",
    "    #   For the example, though, we take the tree output out, as a string, and then parse that in nltk and do our work there.\n",
    "    # Juggling different libraries like this invites some problems wherever your code duct tapes them together,\n",
    "    #   this is here to show it's doable in principle\n",
    "\n",
    "    # Along other things, spacy-benerar added sent._.parse_string.  nltk expects a slightly different markup format - round instand of square brackets\n",
    "    nltk_tree = nltk.Tree.fromstring( sent._.parse_string.replace(\"[\",\"(\").replace(\"]\",\")\") )\n",
    "    display(nltk_tree) # nltk can show us that parse visually  (spacy-benepar doesn't seem to?)\n",
    "\n",
    "    # will count into these. Defaultdict lets us skip the 'initialize with all indices in the list\n",
    "    start_counts = [0]*(len(sent)+1) # +1 because the below is meant to allow [start:end] so end is one higher than the actual last index\n",
    "    end_counts   = [0]*(len(sent)+1)\n",
    "\n",
    "    for c in sent._.constituents:\n",
    "        start_counts[c.start] += 1 \n",
    "        end_counts[c.end] += 1 \n",
    "\n",
    "    diffs   = list( end_counts[i] - start_counts[i] for i in range(min(len(end_counts), len(start_counts))) )\n",
    "    maxdiff = max(diffs)\n",
    "\n",
    "    for toki, tok in enumerate(sent):\n",
    "        print( tok, end=' ' ) # print the word\n",
    "\n",
    "        bracket_diff = diffs[toki]\n",
    "        # print the amount of closing between this and the next word (basically, the amount that the tree depth decreases)\n",
    "        #print( max(0,bracket_diff), end=' ') # negative means opening, right now we don't care about that so report it as zero\n",
    "\n",
    "        # when we see a bunch of brackets,  or it being a considerable fraction of the depth differences overall (might work better in shallower trees)\n",
    "        if bracket_diff >= 3    or  bracket_diff > 0.4*maxdiff: \n",
    "            print( '/' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy-alpino \n",
    "\n",
    "Alpino is a Dutch dependency parser. \n",
    "\n",
    "It looks like spacy's provided dutch models are based on alpino, \n",
    "so you may not care for doing this with extra steps,\n",
    "until you have a specific reason to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy-udpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install spacy_udpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded a model for the 'nl' language\n",
      "['De', 'de', 'DET', 'det', '']\n",
      "['minister', 'minister', 'NOUN', 'nsubj', '']\n",
      "['kan', 'kunnen', 'AUX', 'aux', '']\n",
      "['in', 'in', 'ADP', 'case', '']\n",
      "['Parijs', 'Parijs', 'PROPN', 'obl', '']\n",
      "['opduiken', 'opduiken', 'VERB', 'ROOT', '']\n",
      "['.', '.', 'PUNCT', 'punct', '']\n"
     ]
    }
   ],
   "source": [
    "import spacy_udpipe\n",
    "spacy_udpipe.download(\"nl\")\n",
    "nlp = spacy_udpipe.load(\"nl\")\n",
    "\n",
    "doc = nlp(\"De minister kan in Parijs opduiken.\")\n",
    "for token in doc:\n",
    "    print( [token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_] )\n",
    "for ent in doc.ents:\n",
    "    print( [ent.text, ent.label_] )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
